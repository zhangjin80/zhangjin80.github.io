<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[归并排序算法实现详细注释]]></title>
    <url>%2F2018%2F03%2F09%2F%E5%BD%92%E5%B9%B6%E6%8E%92%E5%BA%8F%E7%AE%97%E6%B3%95%E5%AE%9E%E7%8E%B0%E8%AF%A6%E7%BB%86%E6%B3%A8%E9%87%8A%2F</url>
    <content type="text"><![CDATA[归并排序的思想：分而治之。把一个庞大的数列从中间切分成两个，再分别对这两个数列排序，排序完后再合并，效率会比直接排序高。 那进一步把左右两边不断切分下去，效率也就会越高，切到只剩下一个元素是就不用再进行排序了。这是递归的思想，这就是所谓的归。 合并思想：把一个无序数列，从中间分开，分成左右两边，并递归的对左边和右边进行切分，直到到只剩下一个元素，这时一个元素的序列是有序的，不要再排序了，只需要向上和其盘边的序列进行合并就行了这就是并。 这里整理了一份归并排序的代码并写了详细的注释。123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990public class MergeSort&#123; public static void main(String[] args) &#123;// 初始化一个数组 int[] intArray = &#123;4,2,5,3,3,10,13,4,15,6,13,20,11&#125;; // 先打印未排序的数组 System.out.println(Arrays.toString(intArray)); // 归并排序 mergeSort(intArray); // 打印排序好了的数组 System.out.println(Arrays.toString(intArray)); &#125; public static void mergeSort(int a[])&#123; /** * 为什么要给定下标范围： * 要把一个序列分而治之，需要分别对他的左边和右边切分 */ mergesort(a,0,a.length-1); &#125; /** * 递归方法： * 递归的对数组进行对半切分 * @param a 要排序的数组 * @param first 要排序的数组起始位置 * @param last 要排序的数组的终止位置 * 以两个元素为例进行递归演示： * mergesort&#123;1,2&#125;,0,1 * mid = 0 * mergesort(&#123;1,2&#125;,0,0)---first=last出递归 * mergesort(&#123;1,2&#125;,1,1)---first=last出递归 * mergearray(&#123;1,2&#125;,0,0,1)---放入切分的中间标记，数组左右两边进行合并 */ private static void mergesort(int[] a, int first, int last) &#123; if(first&lt;last)&#123;//递归出口，first=last，只有一个元素时返回继续向下执行 /** * 为什么不能用a.leng/2呢？ * 在递归调用时传的是都是原始数组a，如果用leng的话mid值不会变， * 起不到切分的作用 */ int mid = (first+last)/2; mergesort(a,first,mid); mergesort(a,mid+1,last); mergearray(a,first,mid,last); &#125; &#125; /** * 合并方法： * 把一个数组切分后有序的两端进行合并 * @param a 原始数组 * @param first 要合并的左边数组的开始位置 * @param mid 切分点 * @param last 要合并的右边数组末尾位置 */ private static void mergearray(int[] a, int first, int mid, int last) &#123; /** * 临时数组用于存放有序元素 * 为什么不用int[a.length]创建？ * 因为每次合并的只是a的一部分而已，这样做可以节省空间 */ int[] temp = new int[last+1]; int i = first;//左边数组起始位置 int j = mid+1;//右边数组起始位置 int m = mid;//左边数组终止位置 int n = last;//右边数组终止位置 int k = 0;//临时数组的指针 /** * 比较两个数组栈顶元素大小，把小的存入临时数组 */ while(i&lt;=m&amp;&amp;j&lt;=n)&#123; if(a[i]&lt;=a[j]) temp[k++] = a[i++]; else temp[k++] = a[j++]; &#125; /** * 分别把两个数组剩下的元素存入临时数组 */ while(i&lt;=m)&#123; temp[k++]=a[i++]; &#125; while(j&lt;=n)&#123; temp[k++] = a[j++]; &#125; /** * 把临时数组的值赋给原来的数组 */ for(i=0;i&lt;k;i++)&#123; a[first+i] = temp[i]; &#125; &#125;&#125;]]></content>
      <categories>
        <category>算法</category>
      </categories>
      <tags>
        <tag>算法</tag>
        <tag>排序</tag>
        <tag>java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[二次排序算法（可求不同类别下的Top N）]]></title>
    <url>%2F2018%2F01%2F28%2F%E4%BA%8C%E6%AC%A1%E6%8E%92%E5%BA%8F%E7%AE%97%E6%B3%95%EF%BC%88%E5%8F%AF%E6%B1%82%E4%B8%8D%E5%90%8C%E7%B1%BB%E5%88%AB%E4%B8%8B%E7%9A%84Top-N%EF%BC%89%2F</url>
    <content type="text"><![CDATA[1234一条测试数据示例：math,xuzheng,54,52,86,91,42,85,75课程名，学生姓名，分数（完整的数据放在最后） 需求：求出每门课程参考学生平均成绩最高的学生的信息：课程，姓名和平均分。 思路： 创建课程pojo类，实现WritableComparable接口，实现compareTo方法，先对课程名进行比较，相同再对分数进行比较。 创建分组类实现WritableComparator接口，实现compare方法对课程名进行比较。 在map()中对每行数据进切片，求出平均分，封装进课程对象，然后把改对象作为outKey输出给reduce()。 reduce()每一组的values进行遍历，输出这一组排序好的key。 具体实现课程类CourseScore123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263public class CourseScore implements WritableComparable&lt;CourseScore&gt;&#123; private String courseName; private String studentName; private double avgScore; public CourseScore() &#123; &#125; //根据最后的输出格式实现toString方法 @Override public String toString() &#123; return courseName + "\t" + studentName + "\t" + avgScore; &#125; //对属性序列化 @Override public void write(DataOutput out) throws IOException &#123; out.writeUTF(courseName); out.writeUTF(studentName); out.writeDouble(avgScore); &#125; //反序列化 @Override public void readFields(DataInput in) throws IOException &#123; this.courseName = in.readUTF(); this.studentName = in.readUTF(); this.avgScore = in.readDouble(); &#125; //实现比较器 @Override public int compareTo(CourseScore o) &#123; //先比较课程名 int result = o.courseName.compareTo(this.courseName); //课程名相同，进行平均分的比较 if(result==0)&#123; double temp = o.avgScore-this.avgScore; if(temp==0)&#123; return 0; &#125;else&#123; return temp&gt;0?1:-1; &#125; &#125;else&#123; return result; &#125; &#125; public String getCourseName() &#123; return courseName; &#125; public void setCourseName(String courseName) &#123; this.courseName = courseName; &#125; public String getStudentName() &#123; return studentName; &#125; public void setStudentName(String studentName) &#123; this.studentName = studentName; &#125; public double getAvgScore() &#123; return avgScore; &#125; public void setAvgScore(double avgScore) &#123; this.avgScore = avgScore; &#125;&#125; 分组类1234567891011121314public class ClazzScoreGroupComparator extends WritableComparator &#123; //默认构造器需要调用父类的构造方法 public ClazzScoreGroupComparator() &#123; super(CourseScore.class,true); &#125; //实现分组比较器根据课程名分组就比较课程名 @Override public int compare(WritableComparable a, WritableComparable b) &#123; CourseScore cs1 = (CourseScore)a; CourseScore cs2 = (CourseScore)b; return cs1.getCourseName().compareTo(cs2.getCourseName()); &#125;&#125; MapReduce12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667public class SecondSort &#123; public static void main(String[] args) throws Exception &#123; Configuration conf = new Configuration(); FileSystem fs = FileSystem.get(conf); Job job = Job.getInstance(conf); job.setJarByClass(SecondSort.class); job.setMapperClass(MR_Mapper.class); job.setReducerClass(MR_Reducer.class); job.setOutputKeyClass(CourseScore.class); job.setOutputValueClass(NullWritable.class); //设置分组比较器 job.setGroupingComparatorClass(ClazzScoreGroupComparator.class); Path inputPath = new Path("D:\\bigdata\\flow\\input\\grad"); Path outputPath = new Path("D:\\bigdata\\flow\\output\\q3"); FileInputFormat.setInputPaths(job, inputPath); if(fs.exists(outputPath))&#123; fs.delete(outputPath, true); &#125; FileOutputFormat.setOutputPath(job, outputPath); boolean isDone = job.waitForCompletion(true); System.exit(isDone ? 0 : 1); &#125; /** * 原始数据示例： * math,liujialing,85,86,41,75,93,42,85,75 * english,huangxiaoming,85,86,41,75,93,42,85 */ public static class MR_Mapper extends Mapper&lt;LongWritable, Text, CourseScore, NullWritable&gt;&#123; //创建课程分数类对象 CourseScore cs = new CourseScore(); @Override protected void map(LongWritable key, Text value, Context context) throws IOException, InterruptedException &#123; String[] split = value.toString().split(","); String courseName = split[0]; String studentName = split[1]; double avgScore=0; int sum = 0; for(int i=2;i&lt;split.length;i++)&#123; sum += Integer.parseInt(split[i]); &#125; //求平均分 avgScore=sum/(split.length-2.0); avgScore =(Math.round(avgScore*100)/100.0);//保留两位小数 //把平均分，课程名，学生姓名封装进对象 cs.setAvgScore(avgScore); cs.setCourseName(courseName); cs.setStudentName(studentName); context.write(cs, NullWritable.get()); &#125; &#125; public static class MR_Reducer extends Reducer&lt;CourseScore, NullWritable, CourseScore, NullWritable&gt;&#123; @Override protected void reduce(CourseScore key, Iterable&lt;NullWritable&gt; values, Context context) throws IOException, InterruptedException &#123; //如果只想输出前N项可以设置计数器int count = 0，放在for循环中为N的时候退出 //遍历每一组的values并输出这一组key for(NullWritable v:values)&#123; context.write(key, NullWritable.get()); &#125; &#125; &#125;&#125; 数据流分析 原始数据： 123456computer,huangxiaoming,85,86,41,75,93,42,85english,yangmi,85,41,75,21,85,96,14english,huangdatou,48,58,67,86,15,33,85computer,xuzheng,54,52,86,91,42computer,huangbo,85,42,96,38english,liuyifei,76,95,86,74,68,74,48 map切分后封装到对象中的数据： 123456computer huangxiaoming 72.43english liuyifei 74.43english huangdatou 56.0computer xuzheng 65.0computer huangbo 65.25english yangmi 59.57 分组后的数据 1234567computer huangxiaoming 72.43computer huangbo 65.25computer xuzheng 65.0english liuyifei 74.43english yangmi 59.57english huangdatou 56.0 一般而言，reduce阶段会把具有相同map阶段输出的具有相同key的数据进行聚合，本例中map输出的每一个key都是不同的，但是设置了分组后，reduce就会把每一组的数据进行聚合，我们只要在迭代这组数据的时候输出key，就能把每一组中已经排序好的，不同的key进行输出。 如果不迭代values，直接输出key的话，只会输出这一组的数据的最后一个key，因为这一组前面的数据会被后面的数据覆盖。如在上述示例数据中只会输出：computer,xuzheng,65.0english,huangdatou,56.0 注意： 假如排序规则需要:a b c d 那么分组规则只能从前往后比较 也就是只有如下选择： 123456 - a - a b //先比较a再比较b - a b c //先比较a再比较b再比较c - a b c d ``` ## 测试数据 computer,huangxiaoming,85,86,41,75,93,42,85computer,xuzheng,54,52,86,91,42computer,huangbo,85,42,96,38english,zhaobenshan,54,52,86,91,42,85,75english,liuyifei,85,41,75,21,85,96,14algorithm,liuyifei,75,85,62,48,54,96,15computer,huangjiaju,85,75,86,85,85english,liuyifei,76,95,86,74,68,74,48english,huangdatou,48,58,67,86,15,33,85algorithm,huanglei,76,95,86,74,68,74,48algorithm,huangjiaju,85,75,86,85,85,74,86computer,huangdatou,48,58,67,86,15,33,85english,zhouqi,85,86,41,75,93,42,85,75,55,47,22english,huangbo,85,42,96,38,55,47,22algorithm,liutao,85,75,85,99,66computer,huangzitao,85,86,41,75,93,42,85math,wangbaoqiang,85,86,41,75,93,42,85computer,liujialing,85,41,75,21,85,96,14,74,86computer,liuyifei,75,85,62,48,54,96,15computer,liutao,85,75,85,99,66,88,75,91computer,huanglei,76,95,86,74,68,74,48english,liujialing,75,85,62,48,54,96,15math,huanglei,76,95,86,74,68,74,48math,huangjiaju,85,75,86,85,85,74,86math,liutao,48,58,67,86,15,33,85english,huanglei,85,75,85,99,66,88,75,91math,xuzheng,54,52,86,91,42,85,75math,huangxiaoming,85,75,85,99,66,88,75,91math,liujialing,85,86,41,75,93,42,85,75english,huangxiaoming,85,86,41,75,93,42,85algorithm,huangdatou,48,58,67,86,15,33,85algorithm,huangzitao,85,86,41,75,93,42,85,75`]]></content>
      <categories>
        <category>Hadoop</category>
      </categories>
      <tags>
        <tag>Hadoop</tag>
        <tag>MapReduce算法</tag>
        <tag>算法</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[两张表的连接-reduce join]]></title>
    <url>%2F2017%2F11%2F18%2F%E4%B8%A4%E5%BC%A0%E8%A1%A8%E7%9A%84%E8%BF%9E%E6%8E%A5-reduce-join%2F</url>
    <content type="text"><![CDATA[要点： 两个表中有相同字段，把相同字段的条目，发送到reduce进行拼接 用文件名来区分map中取到的条目是来自哪张表，以便于切分 一个文件块一个split只需要在setup()方法中获取一次文件名就可以 在reduce中进行两张表的拼接，会出现数据倾斜，不适合做大文件操作。 mapper12345678910111213141516171819202122232425262728293031323334353637/**users.dat 数据格式为： 2::M::56::16::70072对应字段中文解释：用户id，性别，年龄，职业，邮政编码ratings.dat 数据格式为： 1::1193::5::978300760对应字段中文解释：用户ID，电影ID，评分，评分时间戳 */public static class MR_Mapper extends Mapper&lt;LongWritable, Text, Text, Text&gt;&#123; String fileName; /** * 在map初始化方法中获取文件名用于区分表 */ @Override protected void setup(Context context) throws IOException, InterruptedException &#123; InputSplit inputSplit = context.getInputSplit(); FileSplit fileSplit = (FileSplit)inputSplit; fileName = fileSplit.getPath().getName(); &#125; @Override protected void map(LongWritable key, Text value, Context context) throws IOException, InterruptedException &#123; String[] split = value.toString().split("::"); String str=""; String id = ""; if(fileName.equals("users.dat"))&#123;//文件名为users.dat为第一张表 id = split[0]; str = 1+"\t" + split[1]+"\t"+split[2]+"\t"+split[3]+"\t"+split[4]; &#125;else&#123; id = split[0]; str = 0+"\t" + split[1]+"\t"+split[2]+"\t"+split[3]; &#125; //以两张表中相同的字段作为outkey输出给reduce outKey.set(id); outValue.set(str); context.write(outKey, outValue); &#125;&#125; reduce阶段：12345678910111213141516171819202122232425262728293031323334353637383940public static class MR_Reducer extends Reducer&lt;Text, Text, Text, Text&gt;&#123; //存储输出value Text outValue = new Text(); //用于存储user表中的字段。 ArrayList&lt;String&gt; userList = new ArrayList&lt;&gt;(); //用于存储user表中的字段。 ArrayList&lt;String&gt; rateList = new ArrayList&lt;&gt;(); @Override protected void reduce(Text key, Iterable&lt;Text&gt; values, Context context) throws IOException, InterruptedException &#123; //分别取出两张表中的条目 for(Text v:values)&#123; String[] split = v.toString().split("\t"); if(split[0].equals("1"))&#123;//标识1，为users.dat表 String temp = split[1]+"\t"+split[2]+"\t"+split[3]+"\t"+split[4]; userList.add(temp); &#125;else&#123; String temp = split[1]+"\t"+split[2]+"\t"+split[3]; rateList.add(temp); &#125; &#125; //对两张表进行连接（内连接操作） for(String user : userList)&#123; for(String rate:rateList)&#123; outValue.set(user + "\t--"+rate); context.write(key, outValue); &#125; &#125; //左外链接操作（右做相反操作就可以了） if(userList.size()&gt;0&amp;&amp;rateList.size()==0)&#123; for(String user : userList)&#123; outValue.set(user); context.write(key, outValue); &#125; &#125; userList.clear(); rateList.clear(); &#125;&#125;]]></content>
      <categories>
        <category>Hadoop</category>
      </categories>
      <tags>
        <tag>Hadoop</tag>
        <tag>MapReduce算法</tag>
        <tag>算法</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[小表连接大表-map join]]></title>
    <url>%2F2017%2F11%2F18%2F%E5%B0%8F%E8%A1%A8%E8%BF%9E%E6%8E%A5%E5%A4%A7%E8%A1%A8-map-join%2F</url>
    <content type="text"><![CDATA[要点： 只能做大表连接小表的操作， 把小表加载当前执行mapTask任务的节点上 只适合实现大表对小表内连接和左外连接，不能实现有外连接。 只能在集群中进行测试。如报java.lang.InterruptedException和java.lang.CaughtException可忽略 分布式组件分布小文件到节点本地的路径： data/hadoopdata/nm-local-dir/filecache/10/ 添加小文件123//设置要分布式的缓存到mapTask节点文件路径//利用DistributedCache分布式缓存组件，把文件分发进行map操作的节点本地job.addCacheFile(new URI(args[2])); mapper实现123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051/**users.dat 数据格式为： 2::M::56::16::70072对应字段中文解释：用户id，性别，年龄，职业，邮政编码 */public static class MR_Mapper extends Mapper&lt;LongWritable, Text, Text, Text&gt;&#123; //用于存储小表数据 HashMap&lt;String , String&gt; users = new HashMap&lt;&gt;(); @Override protected void setup(Mapper&lt;LongWritable, Text, Text, Text&gt;.Context context) throws IOException, InterruptedException &#123; //获得内存本地缓存的小文件的路径 Path[] localCacheFiles = context.getLocalCacheFiles(); String usersFilePath = localCacheFiles[0].toUri().toString(); //通过字符输入流读取进users中 BufferedReader br = new BufferedReader(new FileReader(new File(usersFilePath))); String line=null; while((line = br.readLine())!=null)&#123; String[] split = line.split("::"); String id = split[0]; String mapValue = split[1]+"\t"+split[2]+"\t"+split[3]+"\t"+split[4]; //存储到内存 users.put(id, mapValue); &#125; br.close(); &#125; //ratings.dat 数据格式为： 1::1193::5::978300760 //对应字段中文解释：用户ID，电影ID，评分，评分时间戳 Text outValue = new Text(); Text outKey = new Text(); @Override protected void map(LongWritable key, Text value, Context context) throws IOException, InterruptedException &#123; String[] split = value.toString().split("::"); String userId = split[0]; outKey.set(userId); String strValue = split[1]+"\t"+split[2]+"\t"+split[3]; //如果HashMap中存在当前userId就进行数据拼接 if(users.containsKey(userId))&#123; String mapValue = users.get(userId); outValue.set(strValue+"\t"+mapValue); context.write(outKey, outValue); &#125;else&#123;//做左外连接（不能做右外连接） outValue.set(strValue + "\t"+""+"0"+"\t"+"0"+"\t"+"00000"); &#125; &#125; &#125;]]></content>
      <categories>
        <category>Hadoop</category>
      </categories>
      <tags>
        <tag>Hadoop</tag>
        <tag>MapReduce算法</tag>
        <tag>算法</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[插入排序，二分查找，二维数组打印杨辉三角]]></title>
    <url>%2F2017%2F10%2F18%2F%E6%8F%92%E5%85%A5%E6%8E%92%E5%BA%8F%EF%BC%8C%E4%BA%8C%E5%88%86%E6%9F%A5%E6%89%BE%EF%BC%8C%E4%BA%8C%E7%BB%B4%E6%95%B0%E7%BB%84%E6%89%93%E5%8D%B0%E6%9D%A8%E8%BE%89%E4%B8%89%E8%A7%92%2F</url>
    <content type="text"><![CDATA[插入排序。123456789101112131415161718192021222324//方式一：int arr = &#123;3,11,6,22,1,44&#125;;for(int i=1; i&lt;arr.length; i++)&#123; int temp = arr[i]; int j = i; while(j&gt;0&amp;&amp;arr[j-1]&gt;temp)&#123;//前面的数大于i处的值就往后覆盖，一直到temp的值比这个值小的时候停止 arr[j] = arr[j-1]; j--; &#125; arr[j] = temp;//把temp的值赋给前面元素比它大的位置&#125;//方式二for(int i = 1; i&lt;arr.length; i++)&#123; for(int j=0;j&lt;i;j++)&#123; if(arr[j]&gt;arr[i])&#123; int temp = arr[i]; for(int k=i;k&gt;j;k--)&#123; arr[k] = arr[k-1]; &#125; arr[j]=temp; &#125; &#125;&#125; 有序数组的二分查找。 123456789101112131415161718192021222324public class BinarySearch &#123; public static void main(String[] args) &#123; int[] arr = &#123;1, 5, 7, 12, 19, 22, 25, 29, 33&#125;; int start = 0; int end = arr.length-1; int middle; int value = 25; while (start&lt;end) &#123; middle = (start + end) / 2; if (arr[middle] == value) &#123; System.out.println(middle); break; &#125; if (arr[middle] &gt; value) &#123; end = middle-1; &#125; if (arr[middle] &lt; value) &#123; start = middle+1; &#125; &#125; &#125;&#125; 利用不规则的二维数组存储杨辉三角 1234567891011121314151617int[][] arr = new int[8][]; for(int i=0; i&lt;arr.length; i++)&#123; arr[i] = new int[i+1]; &#125; for(int i=0; i&lt;arr.length; i++)&#123; for(int j=0; j&lt;arr[i].length; j++)&#123; if(j==0||j==i)&#123; arr[i][j] = 1; System.out.print(arr[i][j]); &#125;else&#123; arr[i][j] = arr[i-1][j-1]+arr[i-1][j]; System.out.print(arr[i][j]); &#125; &#125; System.out.println(); &#125;]]></content>
      <categories>
        <category>算法</category>
      </categories>
      <tags>
        <tag>算法</tag>
        <tag>排序</tag>
        <tag>Java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[两种自由]]></title>
    <url>%2F2017%2F09%2F26%2F%E4%B8%A4%E7%A7%8D%E8%87%AA%E7%94%B1%2F</url>
    <content type="text"><![CDATA[精神自由liberal arts一词来源于西方属于西学，有的翻译叫“通识教育”、“素质教育”、“人文教育”、“博雅教育”等，但更确切的讲应该译作“自由技艺”。在古代她是统治者的学问，而在现代是一种培养具有批判性思维，独立人格的学问，也可以叫做拒绝被统治的学问。 这些学问和那些可以直接从事生产赚钱的技术不同，她们是一种软实力，这些软实力中最重要的有三个：批判性思维、交流、解决问题的能力。 批判性思维简单的讲就是对一件事有自己的主见。遇到一件事不随大流，不跟风，要经过调查分析，逻辑判断，多视角思考之后才得出自己的判断。 交流这里讲的是广义上的交流，包括表达自己思想，说服别人，演讲写作等等。在交流中要有自己的风格，也就是人格魅力，他是通过自由技艺的训练而获得的，它不单是个性，还要和别人产生共鸣。 解决问题的能力说的是当你现在遇到问题的时候你要能从你学习到众多知识中找到性质相似的案例，从而知道怎么很好的解决当下的问题。 有了批判性思维你能建立正确的认知。学会有风格的交流你能用你的认知影响别人，再加上一篮子解决问题的方法，那你将不再是一个工具而是一个独立的人了。 这些技艺并不是客观世界的科学，而是主观的体验和看法。他来源于各种人文、艺术学科。 所以，如果你只看专业书籍的话你最终还是工具，乞丐中的王者还是乞丐。只有加上人文和艺术你才能成为自由人。 财富自由怎么获得财富自由呢？一句话就是通过刻意练习，让你的一门手艺达到前5%。或者你把两项达到前25%的手艺组合起来使用。 那下面重点就是怎么样进行刻意练习了。 针对性重复练习。 套路，也就是拿来主义。 要站在前人的肩膀上，不要重复发明轮子。 最重要的套路有两种： 行业经验，书本上找不到，而是行业前辈总结出的经验。你需要找老司机学套路。 学科的概念，一个学科是靠几个大的概念堆出来的，要围绕着这些大的概念把他们弄清楚。比如，经济学20世纪最重要的概念就是发现了交易成本，物理学是发现了熵。只要你了解这些概念清晰的内涵和外延，你就能把这个学科整块的知识拿到手。 拆解练习。不能以赛代练，把大的知识体系拆成为一个个小模块，把复杂问题拆分成简单的小问题逐个攻破。这才有出路。 不断重复重复。 持续做你不会做的事人通常生活在三个区域的划分：舒适区、学习区、恐慌区。大多数人都是生活在舒适区的，但只有学习区才能使人进步，然而想要脱离舒适区是痛苦的。 主动脱离舒适区进入学习情。 刀削面师傅花哨的削面动作在现代只能算是熟练的简单技能，要掌握综合性的复杂技能，就不能一味停留在舒适区不能自拔。不要让自己进入下意识行动状态，要永远挑战意外，不要让自己失控，要时刻用理智指挥自己，强制进入学习区。 被动脱离舒适区进入学习区 好的学习环境，是能获得即使反馈的环境。每一个微小的进步，外界环境都给你一个反馈告诉你是对还是错？建立即时反馈系统，可以被动的让你进入学习区。 总之就是不断重复做你不会做的事，这是很挑战人性本能的活动，但是只要方法得当，你坚持上一段比较长的时间，人人都能做到。 按照马斯洛的需求理论，你必须先追求财富自由，才可能追求精神自由。但这不是绝对的，二者是相辅相成，在追求财富自由的间隙学习一点自由技艺，只会加快你实现财富自由的速度。另外，财富自由可以与生俱来，但精神自由是每个人都需要独立完成的。 我将会用一生的时间去追求这两项自由。]]></content>
      <categories>
        <category>成为你自己</category>
      </categories>
      <tags>
        <tag>人生</tag>
        <tag>自由</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[怎样做到100分]]></title>
    <url>%2F2017%2F09%2F26%2F%E6%80%8E%E6%A0%B7%E5%81%9A%E5%88%B0100%E5%88%86%2F</url>
    <content type="text"><![CDATA[现在很流行一万小时定律，就是你要在某个领域成为专家那只需要在这个领域经过一万小时的练习就可以了。那真的是这样的吗？真的需要一万小时吗？一万小时就会成为专家吗？其实这都不一定，就像一个出租车司机，已经积累了1万小时的里程但是他还是成为不了赛车手一样。罗辑思维的是这期节目告诉你到底应该怎么做才能练成一个高手。建议在原文链接里看完这期节目后再回来看这篇文章会收获更大。 刻意练习一、练习——针对性重复练习。 套路，拿来主义。 前人的知识封装成一个知识罐头，抽象为简洁的东西，拿来就用。最重要的套路： 行业经验，书本上找不到，而是行业前辈总结出的经验。找老司机学套路。 学科的概念，一个学科是靠几个大的概念堆出来的，要围绕着这些大的概念把他们弄清楚。经济学20世纪最重要的概念就是发现了交易成本，物理学是发现了熵。只要你了解这些概念清晰的内涵和外延，你就能把这个学科整坨的知识拿到手。 拆解练习。不能以赛代练，要要把大的知识体系拆碎成为一个个小模块，一个个小知识罐头，分别练习。 最重要的事是——重复。 二、刻意——持续做你不会做的事 三个区域的划分：舒适区—学习区—恐慌区 学习区：脱离舒适区。 农耕时代的勤奋苦练就能成为高手的技能如刀削面师傅等待在现代社会是简单技能，但是现在社会是分工合作的复杂体，要掌握的技能是综合性的复杂技能，不能一味停留在舒适区不能自拔。真正会读书的人是看对自己有挑战的书的人，这种人才是真正有效的。高手是不会让自己进入下意识状态。永远挑战意外永远不会允许自己失控。 被动的脱离舒适区，进入学习区 好的学习环境，是能获得即使反馈的环境。每一个微小的进步，外界环境都给你一个反馈告诉你对错，是否要继续练习。要建立即时反馈系统。 总结：学习的本质就是脱离舒服，没有轻松省力的捷径，学习注定是痛苦的。 三、学习的真相 互联网的信息结构是超文本连接而不是学习。他要人不断的做决策，做选择，而这些决策是被别人引诱而做出来的。（谷歌的核心战略的让用户快进快出），选择是由前额叶做出的，选择并不是在学习。 真正的学习是，不断把新的信息和自身原有的信息结构做缝接，高手的特点就是任何获得的新信息马上能和自己大脑中长期存储的记忆建立联系，信息群被迅速同时激活。做笔记是把学到的东西和自己的知识结构做缝接的过程。收藏的文字要写心得，这是为了与新知识形成互动，把新知识缝接到我原来的知识结构上。知识，是信息之间形成结构进入我们的大脑库存，这个库存不是装东西的存，而是一种体系结构，知识是一种生长出来带结构的东西。 怎样使用工具。有了互联网，人类让自己堕落的更浅薄。我们不能躺在工具产生的便利性上睡大觉挥霍时间在舒适区享受，而是要踏着新工具新技术进一步探索世界，开拓新边疆，向学习区进发。]]></content>
      <categories>
        <category>社会科学</category>
      </categories>
      <tags>
        <tag>人生</tag>
        <tag>刻意练习</tag>
        <tag>学习</tag>
      </tags>
  </entry>
</search>
